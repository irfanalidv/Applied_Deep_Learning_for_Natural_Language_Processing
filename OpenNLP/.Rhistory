?filter_()
??filter_()
filter_()
??filter_()
setwd("C:/Users/Irfanalidv/Desktop/Applied_Deep_Learning_for_Natural_Language_Processing")
library(devtools)
library(devtools)
devtools::install_github("cran/openNLP")
library(openNLP)
library(openNLPdata)
library(openNLP)
library(openNLPdata)
library(rJava)
library(ProjectTemplate)
create.project('OpenNLP')
setwd("OpenNLP/")
load.project()
load.project()
install.packages("C:/Users/Irfanalidv/Downloads/openNLPmodels.en_1.5-1.tar.gz", repos = NULL, type = "source")
library(openNLPmodels.en)
require("NLP")
require("NLP")
s <- paste(c("Pierre Vinken, 61 years old, will join the board as a ",
"nonexecutive director Nov. 29.\n",
"Mr. Vinken is chairman of Elsevier N.V., ",
"the Dutch publishing group."),
collapse = "")
s <- as.String(s)
s
s <- as.String(s)
## Chunking needs word token annotations with POS tags.
sent_token_annotator <- Maxent_Sent_Token_Annotator()
Maxent_Simple_Sent_Tokenizer <-
function(language = "en", probs = FALSE, model = NULL)
{
force(language)
force(probs)
info <- if(is.null(model)) {
package <- if(language == "en")
"openNLPdata"
else
sprintf("openNLPmodels.%s", language)
model <- system.file("models",
sprintf("%s-sent.bin", language),
package = package)
if(model == "") {
msg <-
paste(gettextf("Could not find model file for language '%s'.",
language),
if(system.file(package = package) == "") {
gettextf("Please make sure package '%s' is installed,\navailable from <http://datacube.wu.ac.at/>.",
package)
} else {
gettextf("Apparently, package '%s' is installed\nbut does not provide this model.",
package)
},
sep = "\n")
stop(msg)
}
sprintf("the default model for language '%s'", language)
}
else
"a user-defined model"
## See
## <http://opennlp.apache.org/documentation/1.5.3/manual/opennlp.html#tools.sentdetect.detection.api>.
model <- .jnew("opennlp.tools.sentdetect.SentenceModel",
.jcast(.jnew("java.io.FileInputStream", model),
"java.io.InputStream"))
ref <- .jnew("opennlp.tools.sentdetect.SentenceDetectorME", model)
function(x) {
y <- .jcall(ref,
"[Lopennlp/tools/util/Span;",
"sentPosDetect",
x)
start <- as.integer(sapply(y, .jcall, "I", "getStart")) + 1L
end <- as.integer(sapply(y, .jcall, "I", "getEnd"))
if(probs) {
probs <- .jcall(ref, "[D", "getSentenceProbabilities")
Annotation(NULL,
rep.int("sentence", length(start)),
start,
end,
lapply(probs, single_feature, "prob"))
} else
Span(start, end)
}
}
word_token_annotator <- Maxent_Word_Token_Annotator()
sent_token_annotator
word_token_annotator
force(language)
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
pos_tag_annotator
getAnywhere(annotate())
a3 <- annotate(s,
list(sent_token_annotator,
word_token_annotator,
pos_tag_annotator))
a3
head(a3)
View(a3)
annotate(s, Maxent_Chunk_Annotator(), a3)
View(annotate(s, Maxent_Chunk_Annotator(), a3))
annotate(s, Maxent_Chunk_Annotator(probs = TRUE), a3)
View(annotate(s, Maxent_Chunk_Annotator(probs = TRUE), a3))
View(annotate(s, Maxent_Chunk_Annotator(probs = TRUE), a3))
save.image("C:/Users/Irfanalidv/Desktop/Applied_Deep_Learning_for_Natural_Language_Processing/OpenNLP/env.RData")
require("NLP")
s <- paste(c("Pierre Vinken, 61 years old, will join the board as a ",
"nonexecutive director Nov. 29.\n",
"Mr. Vinken is chairman of Elsevier N.V., ",
"the Dutch publishing group."),
collapse = "")
s <- as.String(s)
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
a2 <- annotate(s, list(sent_token_annotator, word_token_annotator))
a2
entity_annotator <- Maxent_Entity_Annotator()
entity_annotator
annotate(s, entity_annotator, a2)
View(annotate(s, entity_annotator, a2))
## Directly:
entity_annotator(s, a2)
s[entity_annotator(s, a2)]
annotate(s, Maxent_Entity_Annotator(probs = TRUE), a2)
save.image("C:/Users/Irfanalidv/Desktop/Applied_Deep_Learning_for_Natural_Language_Processing/OpenNLP/env_entity.RData")
annotate(s, entity_annotator, a2)
entity_annotator(s, a2)
s[entity_annotator(s, a2)]
require("NLP")
s <- paste(c("Pierre Vinken, 61 years old, will join the board as a ",
"nonexecutive director Nov. 29.\n",
"Mr. Vinken is chairman of Elsevier N.V., ",
"the Dutch publishing group."),
collapse = "")
s <- as.String(s)
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
a2 <- annotate(s, list(sent_token_annotator, word_token_annotator))
Maxent_POS_Tag_Annotator <-
function(language = "en", probs = FALSE, model = NULL)
{
f <- Maxent_Simple_POS_Tagger(language, probs, model)
description <-
sprintf("Computes POS tag annotations using the Apache OpenNLP Maxent Part of Speech tagger employing %s",
environment(f)$info)
for(tag in c("POS_tagset", "POS_tagset_URL")) {
if(!is.na(val <- environment(f)$meta[[tag]]))
attr(f, tag) <- val
}
Simple_POS_Tag_Annotator(f, list(description = description))
}
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
Maxent_Simple_POS_Tagger <-
function(language = "en", probs = FALSE, model = NULL)
{
force(language)
force(probs)
info <- if(is.null(model)) {
package <- if(language == "en")
"openNLPdata"
else
sprintf("openNLPmodels.%s", language)
model <- system.file("models",
sprintf("%s-pos-maxent.bin", language),
package = package)
if(model == "") {
msg <-
paste(gettextf("Could not find model file for language '%s'.",
language),
if(system.file(package = package) == "") {
gettextf("Please make sure package '%s' is installed,\navailable from <http://datacube.wu.ac.at/>.",
package)
} else {
gettextf("Apparently, package '%s' is installed\nbut does not provide this model.",
package)
},
sep = "\n")
stop(msg)
}
sprintf("the default model for language '%s'", language)
}
else
"a user-defined model"
meta <- if(language == "en") {
c(POS_tagset = "en-ptb",
POS_tagset_URL =
"http://www.comp.leeds.ac.uk/ccalas/tagsets/upenn.html")
} else {
package <- sprintf("openNLPmodels.%s", language)
meta <- system.file("models",
sprintf("%s-pos-maxent.dcf", language),
package = package)
if(meta == "")
character()
else
read.dcf(meta)[1L, ]
}
## See
## <http://opennlp.apache.org/documentation/1.5.3/manual/opennlp.html#tools.postagger.tagging.api>.
model <- .jnew("opennlp.tools.postag.POSModel",
.jcast(.jnew("java.io.FileInputStream", model),
"java.io.InputStream"))
ref <- .jnew("opennlp.tools.postag.POSTaggerME", model)
function(x) {
tags <- .jcall(ref, "[S", "tag", .jarray(x))
if(probs) {
probs <- .jcall(ref, "[D", "probs")
Map(c,
lapply(tags, single_feature, "POS"),
lapply(probs, single_feature, "POS_prob"))
} else
tags
}
}
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
pos_tag_annotator
a3 <- annotate(s, pos_tag_annotator, a2)
a3
View(a3)
head(annotate(s, Maxent_POS_Tag_Annotator(probs = TRUE), a2))
a3w <- subset(a3, type == "word")
a3w
tags <- sapply(a3w$features, `[[`, "POS")
tags
table(tags)
sprintf("%s/%s", s[a3w], tags)
sprintf("%s/%s", s[a3w], tags)
annotations_in_spans <-
function(x, y)
{
y <- as.Span(y)
## An annotation node is contained in a span if it does not start
## ahead of the span and does not end later than the span.
ind <- outer(x$start, y$start, ">=") & outer(x$end, y$end, "<=")
lapply(seq_len(ncol(ind)), function(j) x[ind[, j]])
}
a3ws2 <- annotations_in_spans(subset(a3, type == "word"),
subset(a3, type == "sentence")[2L])[[1L]]
a3ws2
sprintf("%s/%s", s[a3ws2], sapply(a3ws2$features, `[[`, "POS"))
save.image("C:/Users/Irfanalidv/Desktop/Applied_Deep_Learning_for_Natural_Language_Processing/OpenNLP/env_POS.RData")
